---
title: "testing"
author: "Asad Tariq"
date: "`r Sys.Date()`"
output: pdf_document
---

## Loading Libraries

```{r}
library(dplyr)
library(tidyverse)
library(caret)
library(tm)
library(randomForest)
library(pROC)
library(glmnet)
```

## Reading the Dataset

```{r}
df <- read_csv("../data/fake_job_postings.csv")
head(df)
```


## Extracting Required Columns

```{r}
df_sub <- select(
  df, title, location, department, company_profile, description,
  requirements, benefits, telecommuting, has_company_logo, has_questions,
  employment_type, required_experience, required_education, sub_industry,
  industry, fraudulent
  )

head(df_sub)
```

## Removing the NAs

```{r}
df_sub$benefits <- ifelse(is.na(df_sub$benefits), 0, 1)
df_sub$location[is.na(df_sub$location)] <- "Not-Specified"
df_sub$department[is.na(df_sub$department)] <- "Not-Specified"
df_sub$employment_type[is.na(df_sub$employment_type)] <- "Not-Specified"
df_sub$required_experience[is.na(df_sub$required_experience)] <- "Not-Specified"
df_sub$required_education[is.na(df_sub$required_education)] <- "Not-Specified"
df_sub$sub_industry[is.na(df_sub$sub_industry)] <- "Not-Specified"
df_sub$industry[is.na(df_sub$industry)] <- "Not-Specified"
```

## Further modifications

```{r}
df_sub$location <- sub(",.*", "", df$location)
```

## Constructing a Job Text column

```{r}
df_sub$text <- paste(df_sub$title, df_sub$location, df_sub$company_profile,
                     df_sub$description, df_sub$requirements, sep = " ")
```

## Dropping the unwanted columns

```{r}
df_sub <- subset(df_sub,
                 select = -c(title, location, company_profile, description,
                             requirements))
```

## Building a corpus from the Text column

```{r}
data_corpus <- Corpus(VectorSource(df_sub$text))
data_corpus <- tm_map(data_corpus, removePunctuation)
data_corpus <- tm_map(data_corpus, removeWords, tm::stopwords(kind = "en"))
data_corpus <- tm_map(data_corpus, stripWhitespace)
data_corpus <- tm_map(data_corpus, stemDocument)
```

### Checking the word frequencies

```{r}
frequencies <- DocumentTermMatrix(data_corpus)
```

```{r}
sparse_data <- removeSparseTerms(frequencies, 0.995)
sparse_data_df <- as.data.frame(as.matrix(sparse_data))
colnames(sparse_data_df) <- make.names(colnames(sparse_data_df))
sparse_data_df$fraudulent <- df_sub$fraudulent
```

## Adding features

```{r}
sparse_data_df <- cbind(df_sub$benefits, df_sub$telecommuting,
                       df_sub$has_company_logo, df_sub$has_questions,
                       sparse_data_df)

colnames(sparse_data_df)[1:4] <- c("benefits", "telecommuting",
                                   "has_company_logo", "has_questions")
```

```{r}
names(sparse_data_df) <- gsub("\\.$", "", names(sparse_data_df))
sparse_data_df <- sparse_data_df[, !duplicated(names(sparse_data_df))]
```

## Fitting a basic Logistic Regression Model

```{r}
binomial_logit.mod <- glm(fraudulent ~ has_company_logo + has_questions + 
                   benefits + telecommuting + multitask + customer*services,
                   data = sparse_data_df,
                   family = "binomial")
summary(binomial_logit.mod)
```

```{r}
# Get predicted probabilities
pred_probs <- predict(binomial_logit.mod, type = "response")

# Classify: use 0.5 as default threshold
pred_class <- ifelse(pred_probs > 0.5, 1, 0)

# # Make sure your actuals are also binary (0/1)
actual <- sparse_data_df$fraudulent
```

### Confusion Matrix

```{r}
# Convert to factor for confusionMatrix
actual <- factor(actual, levels = c("0", "1"))
pred_class <- factor(pred_class, levels = c("0", "1"))

confusionMatrix(pred_class, actual, positive = "1")
```

### F1 Score

```{r}
precision <- posPredValue(pred_class, actual, positive = "1")
recall <- sensitivity(pred_class, actual, positive = "1")
f1 <- 2 * (precision * recall) / (precision + recall)
f1
```

### ROC Curve and AUC

```{r}
roc_obj <- roc(actual, pred_probs)
plot(roc_obj, col = "blue", main = "ROC Curve")
auc(roc_obj)  # AUC score
```


## Weighted Logistic Regression

```{r}
# Assign weights manually (e.g., inversely proportional to class frequency)
weights <- ifelse(sparse_data_df$fraudulent == 1, 10, 1)

weighted_model <- glm(fraudulent ~ has_company_logo + has_questions + 
                        benefits + telecommuting + multitask +
                        customer*services,
                      data = sparse_data_df,
                      family = "binomial",
                      weights = weights)
summary(weighted_model)
```

```{r}
# Get predicted probabilities
pred_probs <- predict(weighted_model, type = "response")

# Classify: use 0.5 as default threshold
pred_class <- ifelse(pred_probs > 0.5, 1, 0)

# # Make sure your actuals are also binary (0/1)
actual <- sparse_data_df$fraudulent
```

### Confusion Matrix

```{r}
# Convert to factor for confusionMatrix
actual <- factor(actual, levels = c("0", "1"))
pred_class <- factor(pred_class, levels = c("0", "1"))

confusionMatrix(pred_class, actual, positive = "1")
```


### F1 Score

```{r}
precision <- posPredValue(pred_class, actual, positive = "1")
recall <- sensitivity(pred_class, actual, positive = "1")
f1 <- 2 * (precision * recall) / (precision + recall)
f1
```

### ROC Curve and AUC

```{r}
roc_obj <- roc(actual, pred_probs)
plot(roc_obj, col = "red", main = "ROC Curve")
auc(roc_obj)  # AUC score
```


## Bayesian Logistic Regression

```{r}
x <- model.matrix(fraudulent ~ has_company_logo + has_questions + 
                    benefits + telecommuting + multitask +
                    customer*services, data = sparse_data_df)[, -1]
y <- sparse_data_df$fraudulent

# Set class weights to address imbalance
weights <- ifelse(y == 1, 10, 1)

set.seed(42)
cv_model <- cv.glmnet(x, y,
                      family = "binomial",
                      alpha = 1,            # Lasso
                      weights = weights,
                      type.measure = "auc", # or "class" or "deviance"
                      nfolds = 5)
```

```{r}
# Plot cross-validation results
plot(cv_model)

# Best lambda (penalty strength)
best_lambda <- cv_model$lambda.min
```


```{r}
# Predicted probabilities
pred_probs <- predict(cv_model, newx = x, s = "lambda.min", type = "response")

# Classify using threshold
pred_class <- ifelse(pred_probs > 0.5, 1, 0)
```

### Confusion Matrix

```{r}
# Confusion matrix
confusionMatrix(as.factor(pred_class), as.factor(y), positive = "1")
```

### F1 Score

```{r}

```


### ROC Curve and AUC

```{r}
# ROC & AUC
roc_obj <- roc(y, as.numeric(pred_probs))
plot(roc_obj)
auc(roc_obj)
```


## Creating a train/test split of the dataset

```{r}
set.seed(123)
train_index <- createDataPartition(sparse_data_df$fraudulent, p = 0.7, list = FALSE)
train_data <- sparse_data_df[train_index, ]
test_data <- sparse_data_df[-train_index, ]

train_data$fraudulent <- as.factor(train_data$fraudulent)
test_data$fraudulent <- as.factor(test_data$fraudulent)
```

## Fitting a Random Forest Model without Resampling
### Random Forest with 100 trees

```{r}
# Assuming your target variable is called 'fraudulent' and it's a factor
rf_model <- randomForest(fraudulent ~ has_company_logo + has_questions + 
                           benefits + multitask + customer*services,
                         data = train_data, ntree = 100, importance = TRUE)
```

### Confusion Matrix

```{r}
# Make predictions
rf_predictions <- predict(rf_model, newdata = test_data)

# Confusion Matrix using caret
conf_matrix <- confusionMatrix(data = rf_predictions,
                               reference = test_data$fraudulent,
                               positive = "1",
                               mode = "everything")

conf_matrix
```

## Oversampling the fraudulent jobs

```{r}
# train_data <- train_data[, !duplicated(names(train_data))]

# 1. Split the training data by class
fraudulent_jobs <- train_data %>% filter(fraudulent == "1")
nonfraudulent_jobs <- train_data %>% filter(fraudulent == "0")

# 2. Oversample the minority class to match the majority
oversampled_fraud <- fraudulent_jobs %>%
  slice_sample(n = nrow(nonfraudulent_jobs), replace = TRUE)

# 3. Combine into balanced training set
train_data_balanced <- bind_rows(nonfraudulent_jobs, oversampled_fraud)

# 4. Shuffle the rows
train_data_balanced <- train_data_balanced %>%
  slice_sample(n = nrow(train_data_balanced))

# Optional: confirm balance
table(train_data_balanced$fraudulent)

```

## Fitting a Random Forest Model with Resampling
### Random Forest with 100 trees

```{r}
rf_model <- randomForest(
  fraudulent ~ has_company_logo + has_questions + benefits + 
    multitask + customer * services,
  data = train_data_balanced,
  ntree = 100,
  importance = TRUE
)

# Predict on the original test set
rf_predictions <- predict(rf_model, newdata = test_data)

# Evaluate performance
conf_matrix <- confusionMatrix(
  data = rf_predictions,
  reference = test_data$fraudulent,
  positive = "1",
  mode = "everything"
)

print(conf_matrix)
```

